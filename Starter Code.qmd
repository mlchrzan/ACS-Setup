---
title: "ACS Setup"
author: "MLC"
format: html
editor: visual
---

# File Setup

```{r libraries, message=FALSE}
library(tidyverse) 
library(janitor) #clean_names()
```

```{r load-in-data, message=FALSE}
social_16_20 <- read_csv("./Data/2016-2020/social 2016-2020.csv")
econ_16_20 <- read_csv("./Data/2016-2020/econ 16-20.csv")
demo_16_20 <- read_csv("./Data/2016-2020/demographic 16-20.csv")
housing_16_20 <- read_csv("./Data/2016-2020/housing 16-20.csv")
varnames_16_20 <- read_csv("./Data/2016-2020/varnames 16-20.csv")
```

# Clean the Files

```{r clean-varnames}
varnames_16_20_clean <- varnames_16_20 |> 
  select(-denominator) |> 
  mutate(value = 1) |> 
  pivot_wider(names_from = vlabel, 
              values_from = value) |> 
  clean_names() |> 
  pivot_longer(cols = -varname, 
               names_to = "label", 
               values_to = 'value') |>
  filter(value == 1) |> 
  select(-value) |> 
  mutate(label = str_replace(label, "number", "n"), 
         label = str_replace(label, "estimate", "est"),
         label = str_replace(label, "percent", "pct"),
         label = str_replace(label, "margin_of_error", "moe")) |> 
  filter(!str_detect(varname, "DP02PR"))

varnames_16_20_clean
```

```{r join-ACS-estimates}
all_16_20 <- left_join(social_16_20, 
          housing_16_20, 
          by = join_by(GeoId, Geography, LEAID, Year, Iteration)) |> 
  left_join(econ_16_20, 
          by = join_by(GeoId, Geography, LEAID, Year, Iteration)) |> 
  left_join(demo_16_20, 
          by = join_by(GeoId, Geography, LEAID, Year, Iteration))

all_16_20
```

```{r clean-and-pivot-acs-estimates}
all_16_20_long <- all_16_20 |>
  mutate(across(starts_with("DP0"), 
                ~if_else(. %in% c('N', 
                                  '(X)', 
                                  '-', 
                                  '******', 
                                  '***', 
                                  '**'), 
                         NA, 
                         as.numeric(.)))) |>
  mutate(across(starts_with("DP0"), as.numeric)) |> 
  pivot_longer(cols = starts_with("DP0"),
               names_to = 'varname',
               values_to = 'values')

all_16_20_long
```

```{r join-varnames}
all_16_20_varnames <- right_join(all_16_20_long, 
                                 varnames_16_20_clean, 
                                 by = join_by(varname)) 

all_16_20_varnames
```

```{r check-for-listed-but-not-collected-vars}
anti_join(all_16_20_varnames, all_16_20_long, 
          by = join_by(GeoId, Geography, LEAID, Year, Iteration, varname, values))

#Will give an error if we seach for those two variables
# all_16_20 |> 
#   select(DP05_86est, DP05_86moe)
```

![](images/clipboard-481330027.png)

```{r remove-empty-rows}
#Remove those two from all_16_20_varnames
all_16_20_varnames <- all_16_20_varnames |> 
  filter(varname != "DP05_86est" & varname != "DP05_86moe")

all_16_20_varnames
```

```{r check-duplicate-varnames}
n_distinct(all_16_20_varnames$varname)
n_distinct(all_16_20_varnames$label)
#Indicates that there are 15 variables that have the same name

#Identifying the variables
dup_varnames <- all_16_20_varnames |>
  dplyr::summarise(n = n(), 
                   .by = c(GeoId, 
                           Geography, 
                           LEAID, 
                           Year,
                           label)) |>
  dplyr::filter(n > 1L)

dup_varnames <- unique(dup_varnames$label)

dup_varnames

#Idenitfy the 'DP0...' labels of the duplicates
all_16_20_varnames |> 
  filter(LEAID == "601620", 
         label %in% dup_varnames) |> 
  arrange(label) |> 
  select(varname, values, label)

#The names do seem to be (mostly) duplicates with the same values, 
#so we'll filter to just one copy of each (and take average of the differing)

#Get varnames to remove
all_dups <- all_16_20_varnames |> 
  filter(LEAID == "601620", 
         label %in% dup_varnames) |> 
  arrange(label) |> 
  select(varname, label) 

all_dups

#UH OH! IS THIS AN ISSUE OF SOME OF THE NAMES BEING CUT FOR LENGTH??
#Check
varnames_16_20 |> 
  filter(varname %in% all_dups$varname) |> 
  arrange(vlabel)
#Doesn't appear to be an issue
```

```{r fix-duplicated-rows}
#Number of Rows with Duplicated variable names = 29,520 (/2 = 14,760)
all_16_20_varnames |>
  dplyr::mutate(dups = n() - 1, 
                .by = c(GeoId, 
                        Geography, 
                        LEAID, 
                        Year,
                        label)) |> 
  filter(dups > 0)

#Summarizing over duplicated variable names (should lose 14,760 rows)
test <- all_16_20_varnames |>
  dplyr::mutate(dups = n() - 1, 
                .by = c(GeoId, 
                        Geography, 
                        LEAID, 
                        Year,
                        label)) |>
  group_by(GeoId, 
           Geography, 
           LEAID, 
           Year,
           label, 
           dups) |>
  summarize(values = mean(values, na.rm = T), 
            .groups = 'keep') |> 
  ungroup()

nrow(all_16_20_varnames) - nrow(test)
#We do lose the correct number of rows!
##Also, note, the Iteration and varname columns are removed here as well!


#Check that the number of distinct labels hasn't changed
n_distinct(all_16_20_varnames$label) == n_distinct(test$label)

#Assign
all_16_20_varnames <- test |> select(-dups)
```

```{r pivot-wide}
all_16_20_final <- all_16_20_varnames |> 
  pivot_wider(names_from = label, 
              values_from = values) 

all_16_20_final
```

```{r prep-and-export}
all_16_20_final <- all_16_20_final |> 
  rename(agency_id = LEAID, 
         agency_name = Geography, 
         acs_est_span = Year) |>
  mutate(start_year = as.integer(str_extract(acs_est_span, "^\\d{4}")), 
         end_year = as.integer(str_extract(acs_est_span, "\\d{4}$")), 
         year = (start_year + end_year) %/% 2) |> 
  select(year, acs_est_span, agency_id, agency_name, everything())

all_16_20_final

write_csv(all_16_20_final, "acs_16_20.csv")
```
